region = geo_loc_row$country
rec = 'daily'
if(input$rec == 2) rec = 'weekly'
date = input$date
numtracks = input$num
dat = scrape_chart(chart, region, rec, date, numtracks)
# add fluid row for each track in obtained dataframe
ui_elems = map(
seq_len(nrow(dat)), function(i) {
# each track title is a hyperlink that goes to the play song page
# TODO: each artist is a hyperlink to the artist info
fluidRow(
column(1,dat$rank[i]),
column(2,img(src=dat$img_url[i], align = "left")),
column(3,tagList(a(dat$track[i], href=dat$song_url[i]))),
column(4,tagList(a(dat$artist[i], href=dat$song_url[i]))),
column(2,dat$streams[i]))
}
)
title = paste("Top", input$num, sep=' ')
if(input$chart == 1) title = paste(title, "Regional Tracks for", sep=' ')
else title = paste(title, "Viral Tracks for", sep=' ')
title = paste(title, geo_loc_row$name, sep=' ')
# popup box showing top tracks
showModal(modalDialog(
title = title,
fluidPage(ui_elems),
easyClose = TRUE,
footer = NULL
))
})
output$map <- renderLeaflet({
#lat and long for spotify regions, ignore first row (dummy row for global)
points = geo_loc[-c(1),c(2,3)]
leaflet() %>%
addProviderTiles(providers$Stamen.TonerLite, options = providerTileOptions(noWrap = TRUE)) %>%
addMarkers(data = points)
})
}
)
base_url = 'https://spotifycharts.com'
# helper function to scrape weekly window that contains the input date
get_week_window = function(date){
# get possible windows (68 total)
windows = read_html('https://spotifycharts.com/regional/global/weekly/latest') %>%
html_nodes('.responsive-select') %>% .[3] %>%
html_nodes('ul li') %>%
html_attr('data-value')
window = ''
# for each possible window, see if input date is within the range
for(i in 1:length(windows)){
day1 = as.Date(substr(windows[i],1,10))
day7 = as.Date(substr(windows[i],13,22))
curr_day = as.Date(date)
# if yes, set the value of 'window' and break out of the for loop
if(day1 <= curr_day & curr_day <= day7){
window = windows[i]
break
}
}
# if can't find a valid window, return most recent weekly ranking so app doesn't crash
if(window=='') return windows[1]
return(window)
}
# get_week_window('2018-04-03')
scrape_chart = function(chart='regional',region='global', recurrence='daily', date='latest', numtracks=5){
# sanity check for tracks- top 200, viral 50
if(chart == 'regional') numtracks = min(numtracks, 200)
if(chart == 'viral') numtracks = min(numtracks, 50)
if(recurrence == 'weekly') date = get_week_window(date)
url = paste(base_url, chart, region, recurrence, date, sep='/')
res = read_html(url)
# sanity check for valid url
if(length(res %>% html_nodes('div.not-found'))!=0)
stop(paste(url, 'is not a valid Spotify Charts url. Please try again'))
# get table contents
elms = res %>% html_nodes('tbody tr')
# instantiate empty data frame
dat = data.frame(rank=integer(),
track=character(),
artist=character(),
streams=integer(),
song_url=character(),
img_url=character())
# for each track, extract the track, artist, ... etc, and bind to the dataframe
for(i in 1:numtracks){
track = elms[i] %>% html_nodes('td.chart-table-track strong') %>% html_text()
artist = elms[i] %>% html_nodes('td.chart-table-track span') %>% html_text() %>% str_replace('by ', '')
streams = elms[i] %>% html_nodes('td.chart-table-streams') %>% html_text() %>% str_replace_all(',','') %>% as.numeric()
song_url = elms[i] %>% html_nodes('td.chart-table-image a') %>% html_attr('href')
img_url = elms[i] %>% html_nodes('td.chart-table-image img') %>% html_attr('src')
dat = rbind(dat, cbind(rank=as.numeric(i),track, artist, streams, song_url, img_url))
}
return(dat)
}
get_week_window('2018-04-28')
base_url = 'https://spotifycharts.com'
get_week_window = function(date){
# get possible windows (68 total)
windows = read_html('https://spotifycharts.com/regional/global/weekly/latest') %>%
html_nodes('.responsive-select') %>% .[3] %>%
html_nodes('ul li') %>%
html_attr('data-value')
window = ''
# for each possible window, see if input date is within the range
for(i in 1:length(windows)){
day1 = as.Date(substr(windows[i],1,10))
day7 = as.Date(substr(windows[i],13,22))
curr_day = as.Date(date)
# if yes, set the value of 'window' and break out of the for loop
if(day1 <= curr_day & curr_day <= day7){
window = windows[i]
break
}
}
# if can't find a valid window, return most recent weekly ranking so app doesn't crash
if(window=='') return windows[1]
return(window)
}
get_week_window = function(date){
# get possible windows (68 total)
windows = read_html('https://spotifycharts.com/regional/global/weekly/latest') %>%
html_nodes('.responsive-select') %>% .[3] %>%
html_nodes('ul li') %>%
html_attr('data-value')
window = ''
# for each possible window, see if input date is within the range
for(i in 1:length(windows)){
day1 = as.Date(substr(windows[i],1,10))
day7 = as.Date(substr(windows[i],13,22))
curr_day = as.Date(date)
# if yes, set the value of 'window' and break out of the for loop
if(day1 <= curr_day & curr_day <= day7){
window = windows[i]
break
}
}
# if can't find a valid window, return most recent weekly ranking so app doesn't crash
if(window=='') return windows[1]
return(window)
}
base_url = 'https://spotifycharts.com'
# helper function to scrape weekly window that contains the input date
get_week_window = function(date){
# get possible windows (68 total)
windows = read_html('https://spotifycharts.com/regional/global/weekly/latest') %>%
html_nodes('.responsive-select') %>% .[3] %>%
html_nodes('ul li') %>%
html_attr('data-value')
window = ''
# for each possible window, see if input date is within the range
for(i in 1:length(windows)){
day1 = as.Date(substr(windows[i],1,10))
day7 = as.Date(substr(windows[i],13,22))
curr_day = as.Date(date)
# if yes, set the value of 'window' and break out of the for loop
if(day1 <= curr_day & curr_day <= day7){
window = windows[i]
break
}
}
# if can't find a valid window, return most recent weekly ranking so app doesn't crash
if(window=='') return(windows[1])
return(window)
}
# get_week_window('2018-04-03')
scrape_chart = function(chart='regional',region='global', recurrence='daily', date='latest', numtracks=5){
# sanity check for tracks- top 200, viral 50
if(chart == 'regional') numtracks = min(numtracks, 200)
if(chart == 'viral') numtracks = min(numtracks, 50)
if(recurrence == 'weekly') date = get_week_window(date)
url = paste(base_url, chart, region, recurrence, date, sep='/')
res = read_html(url)
# sanity check for valid url
if(length(res %>% html_nodes('div.not-found'))!=0)
stop(paste(url, 'is not a valid Spotify Charts url. Please try again'))
# get table contents
elms = res %>% html_nodes('tbody tr')
# instantiate empty data frame
dat = data.frame(rank=integer(),
track=character(),
artist=character(),
streams=integer(),
song_url=character(),
img_url=character())
# for each track, extract the track, artist, ... etc, and bind to the dataframe
for(i in 1:numtracks){
track = elms[i] %>% html_nodes('td.chart-table-track strong') %>% html_text()
artist = elms[i] %>% html_nodes('td.chart-table-track span') %>% html_text() %>% str_replace('by ', '')
streams = elms[i] %>% html_nodes('td.chart-table-streams') %>% html_text() %>% str_replace_all(',','') %>% as.numeric()
song_url = elms[i] %>% html_nodes('td.chart-table-image a') %>% html_attr('href')
img_url = elms[i] %>% html_nodes('td.chart-table-image img') %>% html_attr('src')
dat = rbind(dat, cbind(rank=as.numeric(i),track, artist, streams, song_url, img_url))
}
return(dat)
}
library(shiny)
library(shinythemes)
library(leaflet)
geo_loc = read.csv('geo_loc.csv', header=TRUE)
geo_loc$country = as.character(geo_loc$country)
shinyApp(
ui = fluidPage(theme = shinytheme('darkly'),
titlePanel("Spotify Charts"),
sidebarLayout(
sidebarPanel(
radioButtons('chart', label='Chart:', choices = list('Regional Top'=1, 'Viral'=2), selected = 1),
# selectInput('region', 'Region:', geo_loc$name),
radioButtons('rec', label='Recurrence:', choices = list('Daily'=1, 'Weekly'=2), selected = 1),
dateInput("date", label = "Date:", value=Sys.Date()-1, min='2017-01-01', max=Sys.Date()-1),
sliderInput("num", label = "Number of Tracks", min = 1, max = 200, value = 5),
actionButton("global", label = "View Global Rankings")
),
mainPanel(
leafletOutput("map", height=600)
)
)
),
server = function(input, output, session)
{
# view global rankings
observeEvent(input$global, {
# extract function inputs
chart = 'regional'
if(input$chart == 2) chart = 'viral'
rec = 'daily'
if(input$rec == 2) rec = 'weekly'
date = input$date
numtracks = input$num
dat = scrape_chart(chart=chart, recurrence=rec, date=date, numtracks=numtracks)
# add fluid row for each track in obtained dataframe
ui_elems = map(
seq_len(nrow(dat)), function(i) {
# each track title is a hyperlink that goes to the play song page
# TODO: each artist is a hyperlink to the artist info
fluidRow(
column(1,dat$rank[i]),
column(2,img(src=dat$img_url[i], align = "left")),
column(3,tagList(a(dat$track[i], href=dat$song_url[i]))),
column(4,tagList(a(dat$artist[i], href=dat$song_url[i]))),
column(2,dat$streams[i]))
}
)
title = paste("Top", input$num, sep=' ')
if(input$chart == 1) title = paste(title, "Global Regional Tracks", sep=' ')
else title = paste(title, "Global Viral Tracks", sep=' ')
# popup box showing top tracks
showModal(modalDialog(
title = title,
fluidPage(ui_elems),
easyClose = TRUE,
footer = NULL
))
})
# update max value of number of tracks, depending on type of chart (top vs. viral)
observeEvent(input$chart, {
if(input$chart == 1) updateSliderInput(session, "num", max=200)
else updateSliderInput(session, "num", max=50)
})
# observe clicks on map markers
observeEvent(input$map_marker_click, {
click = input$map_marker_click
# get row for country that corresponds to this lat and long
geo_loc_row = geo_loc[which(geo_loc$lat==click$lat & geo_loc$long==click$lng),]
# extract function inputs
chart = 'regional'
if(input$chart == 2) chart = 'viral'
region = geo_loc_row$country
rec = 'daily'
if(input$rec == 2) rec = 'weekly'
date = input$date
numtracks = input$num
dat = scrape_chart(chart, region, rec, date, numtracks)
# add fluid row for each track in obtained dataframe
ui_elems = map(
seq_len(nrow(dat)), function(i) {
# each track title is a hyperlink that goes to the play song page
# TODO: each artist is a hyperlink to the artist info
fluidRow(
column(1,dat$rank[i]),
column(2,img(src=dat$img_url[i], align = "left")),
column(3,tagList(a(dat$track[i], href=dat$song_url[i]))),
column(4,tagList(a(dat$artist[i], href=dat$song_url[i]))),
column(2,dat$streams[i]))
}
)
title = paste("Top", input$num, sep=' ')
if(input$chart == 1) title = paste(title, "Regional Tracks for", sep=' ')
else title = paste(title, "Viral Tracks for", sep=' ')
title = paste(title, geo_loc_row$name, sep=' ')
# popup box showing top tracks
showModal(modalDialog(
title = title,
fluidPage(ui_elems),
easyClose = TRUE,
footer = NULL
))
})
output$map <- renderLeaflet({
#lat and long for spotify regions, ignore first row (dummy row for global)
points = geo_loc[-c(1),c(2,3)]
leaflet() %>%
addProviderTiles(providers$Stamen.TonerLite, options = providerTileOptions(noWrap = TRUE)) %>%
addMarkers(data = points)
})
}
)
library(shiny)
library(shinythemes)
library(leaflet)
geo_loc = read.csv('geo_loc.csv', header=TRUE)
geo_loc$country = as.character(geo_loc$country)
shinyApp(
ui = fluidPage(theme = shinytheme('darkly'),
titlePanel("Spotify Charts"),
sidebarLayout(
sidebarPanel(
radioButtons('chart', label='Chart:', choices = list('Regional Top'=1, 'Viral'=2), selected = 1),
# selectInput('region', 'Region:', geo_loc$name),
radioButtons('rec', label='Recurrence:', choices = list('Daily'=1, 'Weekly'=2), selected = 1),
dateInput("date", label = "Date:", value=Sys.Date()-1, min='2017-01-01', max=Sys.Date()-1),
sliderInput("num", label = "Number of Tracks", min = 1, max = 200, value = 5),
actionButton("global", label = "View Global Rankings")
),
mainPanel(
leafletOutput("map", height=600)
)
)
),
server = function(input, output, session)
{
# view global rankings
observeEvent(input$global, {
# extract function inputs
chart = 'regional'
if(input$chart == 2) chart = 'viral'
rec = 'daily'
if(input$rec == 2) rec = 'weekly'
date = input$date
numtracks = input$num
dat = scrape_chart(chart=chart, recurrence=rec, date=date, numtracks=numtracks)
# add fluid row for each track in obtained dataframe
ui_elems = map(
seq_len(nrow(dat)), function(i) {
# each track title is a hyperlink that goes to the play song page
# TODO: each artist is a hyperlink to the artist info
fluidRow(
column(1,dat$rank[i]),
column(2,img(src=dat$img_url[i], align = "left")),
column(3,tagList(a(dat$track[i], href=dat$song_url[i]))),
column(4,tagList(a(dat$artist[i], href=dat$song_url[i]))),
column(2,dat$streams[i]))
}
)
title = paste("Top", input$num, sep=' ')
if(input$chart == 1) title = paste(title, "Global Regional Tracks", sep=' ')
else title = paste(title, "Global Viral Tracks", sep=' ')
# popup box showing top tracks
showModal(modalDialog(
title = title,
fluidPage(ui_elems),
easyClose = TRUE,
footer = NULL
))
})
# update max value of number of tracks, depending on type of chart (top vs. viral)
observeEvent(input$chart, {
if(input$chart == 1) updateSliderInput(session, "num", max=200)
else updateSliderInput(session, "num", max=50)
})
# observe clicks on map markers
observeEvent(input$map_marker_click, {
click = input$map_marker_click
# get row for country that corresponds to this lat and long
geo_loc_row = geo_loc[which(geo_loc$lat==click$lat & geo_loc$long==click$lng),]
# extract function inputs
chart = 'regional'
if(input$chart == 2) chart = 'viral'
region = geo_loc_row$country
rec = 'daily'
if(input$rec == 2) rec = 'weekly'
date = input$date
numtracks = input$num
dat = scrape_chart(chart, region, rec, date, numtracks)
# add fluid row for each track in obtained dataframe
ui_elems = map(
seq_len(nrow(dat)), function(i) {
# each track title is a hyperlink that goes to the play song page
# TODO: each artist is a hyperlink to the artist info
fluidRow(
column(1,dat$rank[i]),
column(2,img(src=dat$img_url[i], align = "left")),
column(3,tagList(a(dat$track[i], href=dat$song_url[i]))),
column(4,tagList(a(dat$artist[i], href=dat$song_url[i]))),
column(2,dat$streams[i]))
}
)
title = paste("Top", input$num, sep=' ')
if(input$chart == 1) title = paste(title, "Regional Tracks for", sep=' ')
else title = paste(title, "Viral Tracks for", sep=' ')
title = paste(title, geo_loc_row$name, sep=' ')
# popup box showing top tracks
showModal(modalDialog(
title = title,
fluidPage(ui_elems),
easyClose = TRUE,
footer = NULL
))
})
output$map <- renderLeaflet({
#lat and long for spotify regions, ignore first row (dummy row for global)
points = geo_loc[-c(1),c(2,3)]
leaflet() %>%
addProviderTiles(providers$Stamen.TonerLite, options = providerTileOptions(noWrap = TRUE)) %>%
addMarkers(data = points)
})
}
)
stem_subjs = c("Biology", "Chemistry", "Neuroscience", "BME", "ECE", "Mechanical Engineering",
"Computer Science", "Math", "Statistics", "Environmental Science", "Environmental Engineering")
extract_majors = function(s){
split = unlist(strsplit(s, ","))
split = trimws(split)
return(split)
}
is_stem = function(majors){
isStem = any(stem_subjs %in% majors)
if(isStem) return(1)
else return(0)
}
refresh_dat = function(){
# refresh OAuth token
gs_auth()
# rescrape data from google sheet
gsheet_title = "Survey: Technological Modifications of the Human  (Responses)"
gsheet = gs_title(gsheet_title)
ws_title = gs_ws_ls(gsheet)[1]
dat = gs_read(ss=gsheet, ws=ws_title)
dat = as.data.frame(dat)
# remove timestamp and extra column at end
dat = dat[c(-1, -ncol(dat))]
# switch order of B3 and B4, error in ordering of initial survey
dat = dat[,c(1,2,3,4,5,6,8,7,9,10,11,12,13,14,15,16,17,18)]
# set new column names for brevity
qcols = c(paste('A', seq(1,4), sep=""),
paste('B', seq(1,4), sep=""),
paste('C', seq(1,4), sep=""),
paste('D', seq(1,4), sep=""))
colnames(dat) = c(qcols, 'Majors', colnames(dat)[18])
# extract numerical graduating year
dat$Year = as.numeric(str_extract_all(dat$Year, "[0-9]+"))
dat$Year = as.factor(dat$Year)
# extract majors and create STEM column
dat$Majors = sapply(dat$Majors, extract_majors)
dat$Stem = sapply(dat$Majors, is_stem)
saveRDS(dat, file = "survey_dat.rds")
return(dat)
}
dat = readRDS(file = 'survey_dat.rds')
getwd
getwd()
setwd('/Users/AnnieTang/Documents/DUKE/17-18/GSF 366/gsf_shiny_app')
dat = readRDS(file = 'survey_dat.rds')
dat = dat %>% gather(scenario, Response, -Year, -Majors, -Stem)
library(purrr)
dat = dat %>% gather(scenario, Response, -Year, -Majors, -Stem)
?gather
??gather
library(tidyr)
dat = dat %>% gather(scenario, Response, -Year, -Majors, -Stem)
colnames(dat) = c('majors', 'year', 'stem', 'scenario', 'response')
View(dat)
dat$response = as.factor(dat$response)
dat = dat[,c(5,4,1,2,3)]
dat$sophomore = as.numeric(dat$year == '2020')
dat$sophomore = as.factor(dat$sophomore)
dat$junior = as.numeric(dat$year == '2019')
dat$junior = as.factor(dat$junior)
dat$senior = as.numeric(dat$year == '2018')
dat$senior = as.factor(dat$senior)
dat = dat[-c(4)]
ubiq = c('A1', 'B1', 'C1', 'C2', 'D1')
dat$ubiquitous = as.numeric(dat$scenario %in% ubiq)
dat$ubiquitous = as.factor(dat$ubiquitous)
rest = c('A2', 'A3', 'B1', 'B2', 'C2', 'D2')
dat$restorative = as.numeric(dat$scenario %in% rest)
dat$restorative = as.factor(dat$restorative)
enh = c('A4', 'D1', 'D3', 'D4')
dat$enhancing = as.numeric(dat$scenario %in% enh)
dat$enhancing = as.factor(dat$enhancing)
gen = c('B3', 'B4', 'C3', 'C4', 'D3', 'D4')
dat$generative = as.numeric(dat$scenario %in% gen)
dat$generative = as.factor(dat$generative)
inv = c('A2', 'A3', 'A4', 'B1','B2','B3','B4','C2','C4','D2','D3','D4')
dat$invasive = as.numeric(dat$scenario %in% inv)
dat$invasive = as.factor(dat$invasive)
irr = c('A1', 'A2', 'A3', 'A4', 'B2', 'B3', 'B4', 'C1' ,'C2', 'C3', 'C4', 'D1')
dat$irreversible = as.numeric(dat$scenario %in% irr)
dat$irreversible = as.factor(dat$irreversible)
her = c('A2', 'A3', 'A4', 'C4')
dat$hereditary = as.numeric(dat$scenario %in% her)
dat$hereditary = as.factor(dat$hereditary)
library(nnet)
shiny::runApp()
library(nnet)
dat$response2 = relevel(dat$response, ref='2: Neutral')
test = multinom(response2 ~ stem + sophomore + junior + senior + ubiquitous + restorative
+ enhancing + generative + invasive + irreversible + hereditary, data=dat)
summary(test)
z = summary(test)$coefficients/summary(test)$standard.errors
p = (1-pnorm(abs(z),0,1)) * 2
p
